!!python/object:argparse.Namespace
#
across_channels: 0
added_std: 0.001
all: 1  # should all methods be run
all_obs: 0  # should all data dimensions be observed
baseline: 1.0 
baselined: false
beta: 1.0
binarise: 1
class_scale: 0.0
combination: regular # mask combination with the data
#
dataparams: z1d_negCorr_diff_error 
datasamples: 10000

earlystop: 2500 # effectively disable it / harmful to naive method
epochs: 3

eval_plot_only_all_obs: 0
exp: masked
fig_root: ./runs/
fraction_full: 0.25 # fraction of data to be observed
freeze_after_training: 0 # freeze the decoder after training
freeze_decoder: 1 # freeze the decoder from the start (gt generative model)
full_loss: 0 # use both masked and observed data for rec loss
imputeoff: 1 # impute off for actually missing data
latent_size: 1 # size of the latent space
latentclassification: 0 # classification on the latent space

learning_rate: 0.001
list_len: 3 # number of different dataset parameters
loss_type: regular
masked: true
mean_impute: 0
method: 0 # method choose one of them from commandline     methods = [0 : 'zero_imputation_mask_concatenated',1: 'zero_imputation', 2: 'zero_imputation_baselined',3: 'zero_imputation_mask_concatenated_encoder_only']
n_data_dims: 20
n_hidden: 60
n_masked_vals: 10
n_samples: 128
nonlin: 2
offline: 0
one_impute: 0
only_obs: 0
pass_mask: true
posterior_reg: 0
print_every: 100
project_name: glvm_in_maskedvae
task_name: glvm
random_impute: 0
random_masks: 0
run_test: 0
sampling: 1
seed: 42
shorttest: 0
shrinkmask: 0
specified_masks: 0
store_model: 0
# batch size
test_batch_size: 4000
valid_batch_size: 4000
batch_size: 1000

uncertainty: 1  # should uncertainty be learned explicitly
unique_masks: 3 # number of unique masks
val_impute: 1 # baseline corresponds to mean making it easier for naive
visualise: 1 # visualise the results during training
warmup_range: 30 # number of epochs to warmup
watchmodel: 0
wholedata: 0
# data dimensions
z_dim: 1
x_dim: 20