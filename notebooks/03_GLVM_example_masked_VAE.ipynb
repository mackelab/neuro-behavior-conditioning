{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import random\n",
    "from argparse import Namespace\n",
    "from datetime import datetime\n",
    "from os.path import expanduser\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "from maskedvae.model.models import ModelGLVM\n",
    "from maskedvae.model.networks import GLVM_VAE\n",
    "from maskedvae.utils.utils import ensure_directory, save_pickle, save_yaml\n",
    "from maskedvae.model.masks import MultipleDimGauss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up configuration and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 42, # random seed\n",
    "    \"epochs\": 100, # number of epochs\n",
    "    \"beta\": 1.0, # beta value for beta-vae\n",
    "    \"all_obs\": 0, # 1 for all observed data\n",
    "    \"visualise\": 0, # save visualisations during training\n",
    "    \"shorttest\": 0, # load shorter dataset for testing run setup\n",
    "    \"all\": 1, # run all methods in the list \n",
    "    \"method\": 0, # specify which method if all=0\n",
    "    \"one_impute\": 0, # impute 1 for all masked values\n",
    "    \"val_impute\": 1, # impute a specific value \n",
    "    \"mean_impute\": 0, # impute a respective mean \n",
    "    \"random_impute\": 0, # impute a random value mean \n",
    "    \"list_len\": 1, # only one data condition C, noise\n",
    "    \"task_name\": \"glvm\", # task name\n",
    "    \"exp\": \"glvm\", # experiment name wandb\n",
    "    \"offline\": 1, #1 sets wandb offline\n",
    "    \"cross_loss\": 0, # alternative training loss off\n",
    "    \"full_loss\": 0, # alternative training loss on all data off\n",
    "    \"dropout\": 0.0, # dropout to compare to simple dropout off\n",
    "}\n",
    "if config[\"offline\"]:\n",
    "    os.environ[\"WANDB_MODE\"] = \"offline\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_directory = \"../data/\"\n",
    "run_directory = \"../runs/\"\n",
    "ensure_directory(run_directory)\n",
    "\n",
    "with open('../configs/glvm/fit_config.yml', \"r\") as f:\n",
    "    data_conf = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# update config with data_conf\n",
    "# the second overwrites the first - comman line will beat config\n",
    "args_dict = {**data_conf.__dict__, **config}\n",
    "args = Namespace(**args_dict)\n",
    "\n",
    "assert np.abs(args.fraction_full - 1 / (args.unique_masks + 1)) <= 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seeds to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup torch and seeds\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(1)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "method_handle = copy.copy(args.method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training, validation and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = 0 \n",
    "dataset_train = torch.load(\n",
    "    f\"{data_directory:s}/glvm/20_dim_1_dim/data_train_{c_id:d}.pt\"\n",
    ")\n",
    "dataset_valid = torch.load(\n",
    "    f\"{data_directory:s}/glvm/20_dim_1_dim/data_valid_{c_id:d}.pt\"\n",
    ")\n",
    "dataset_test = torch.load(\n",
    "    f\"{data_directory:s}/glvm/20_dim_1_dim/data_test_{c_id:d}.pt\"\n",
    ")\n",
    "\n",
    "args.C = dataset_train.C\n",
    "args.d = dataset_train.d\n",
    "args.z_prior = np.stack((np.zeros(args.z_dim), np.ones(args.z_dim)))\n",
    "args.noise = dataset_train.noise\n",
    "\n",
    "print(\"train \", len(dataset_train), \"valid \", len(dataset_valid), \"test \", len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the running modes: masked vs naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"zero_imputation_mask_concatenated_encoder_only\", # masked with all_obs = 0\n",
    "    \"zero_imputation\", # naive with all_obs = 1\n",
    "]\n",
    "# short names for WandB\n",
    "method_short = [\n",
    "    \"enc-mask-\",  # masekd\n",
    "    \"zero-\",    # naive\n",
    "]\n",
    "meth_labels = ['masked', 'naive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging of losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs = {\n",
    "    method: {\n",
    "        \"elbo\": [],\n",
    "        \"kl\": [],\n",
    "        \"rec_loss\": [],\n",
    "        \"elbo_val\": [],\n",
    "        \"kl_val\": [],\n",
    "        \"rec_loss_val\": [],\n",
    "        \"masked_rec_loss\": [],\n",
    "        \"masked_rec_loss_val\": [],\n",
    "        \"observed_mse\": [],\n",
    "        \"masked_mse\": [],\n",
    "        \"time_stamp_val\": [],\n",
    "    }\n",
    "    for method in methods\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the Mask generator + run paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.ts = datetime.now().strftime(\"%d%m%Y_%H%M\" \"%S\")  # more easily readable\n",
    "\n",
    "# Specify the masking generator\n",
    "args.generator = MultipleDimGauss\n",
    "# Specify which non linearity to use for the networks\n",
    "nonlin_mapping = {0: nn.Identity(), 1: nn.ELU(), 2: nn.ReLU(), 3: nn.Sigmoid()}\n",
    "args.nonlin_fn = nonlin_mapping.get(args.nonlin, nn.Identity())\n",
    "    \n",
    "# ensure either one or mean imputation if both zero standard zero imputation\n",
    "args.mean_impute = not args.one_impute and args.mean_impute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training for both naive and masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, method in enumerate(methods):\n",
    "    # pass the right logs to network\n",
    "    args.method = method\n",
    "    \n",
    "    if args.method == \"zero_imputation\":\n",
    "        args.all_obs = 1\n",
    "        args.exp = \"naive\"\n",
    "    elif args.method == \"zero_imputation_mask_concatenated_encoder_only\":\n",
    "        args.all_obs = 0\n",
    "        args.exp = \"masked\"     \n",
    "           \n",
    "    name_tag = f\"xdims_{args.x_dim}_C_{args.C[0][0]:.2f}_sig_{args.noise[0][0]:.2f}\"\n",
    "\n",
    "    if args.freeze_decoder and args.loss_type != \"regular\":\n",
    "        args.loss_type = \"regular\"\n",
    "        print(\"The decoder is frozen -> switching loss type to regular...\")\n",
    "        name_tag = f\"_frozen{name_tag}\"\n",
    "    print(name_tag)\n",
    "    # Initialize the Weights and Biases (wandb) run \n",
    "    run = wandb.init(\n",
    "        project=args.project_name,\n",
    "        group=f\"{args.exp}{name_tag}\",\n",
    "        name=f\"{method_short[i]}{args.ts}\",\n",
    "        reinit=True,\n",
    "        config=args,\n",
    "        dir=run_directory\n",
    "    )\n",
    "\n",
    "    # Setup the directory for storing figures \n",
    "    figs_directory = os.path.join(wandb.run.dir, \"figs\")\n",
    "    os.makedirs(figs_directory, exist_ok=True)  # os.makedirs can create directories and won't throw an error if the directory already exists\n",
    "    args.fig_root = run_directory\n",
    "    # Update wandb configuration with the figures directory path\n",
    "    args.fig_dir = figs_directory\n",
    "    wandb.config.update({\"fig_dir\": args.fig_dir}, allow_val_change=True)\n",
    "\n",
    "    print(\"Masked model...\")\n",
    "    model = ModelGLVM(\n",
    "        args=args,\n",
    "        dataset_train=dataset_train,\n",
    "        dataset_valid=dataset_valid,\n",
    "        dataset_test=dataset_test,\n",
    "        logs=logs[method],\n",
    "        device=device,\n",
    "        inference_model=GLVM_VAE,\n",
    "        Generator=args.generator,\n",
    "        nonlin=args.nonlin_fn,\n",
    "        dropout=args.dropout,\n",
    "    )\n",
    "\n",
    "    print(\" ---------- begin model fit ---------------\")\n",
    "    print(method)\n",
    "\n",
    "    model.fit()\n",
    "    print(\" ---------- end model fit ---------------\")\n",
    "    print(\"  \")\n",
    "\n",
    "    model_path = os.path.join(model.args.fig_root, str(model.ts), model.method)\n",
    "    ensure_directory(model_path)\n",
    "\n",
    "    # save logs and args dictionary\n",
    "    save_pickle(model.logs, os.path.join(model_path, \"logs.pkl\"))\n",
    "    save_pickle(model.args, os.path.join(model_path, \"args.pkl\"))\n",
    "    save_yaml(model.args, os.path.join(model_path, \"args.yml\"))\n",
    "\n",
    "    model.train_loader = 0\n",
    "    model.test_loader = 0\n",
    "    model.validation_loader = 0\n",
    "    \n",
    "    # save the model\n",
    "    if not model.args.watchmodel:\n",
    "        model_filepath = os.path.join(model_path, \"model_end_of_training.pt\")\n",
    "        torch.save(model, model_filepath)\n",
    "        torch.save(model, os.path.join(wandb.run.dir, \"model_end_of_training.pt\"))\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "# ------------------------ end loop over methods ----------------------------------------\n",
    "\n",
    "joint_directory_path = os.path.join(model.args.fig_root, str(model.ts))\n",
    "ensure_directory(joint_directory_path)\n",
    "save_pickle(model.logs, os.path.join(joint_directory_path, \"logs.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise the loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskedvae.plotting.plotting import plot_losses\n",
    "from maskedvae.plotting.plotting_utils import cm2inch\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=cm2inch((30, 6)))\n",
    "plot_losses(logs, methods, ax=axes[0], log='elbo', ylabel='- elbo', xlabel='iteration')\n",
    "plot_losses(logs, methods, ax=axes[1], log='elbo_val', ylabel='- elbo', xlabel='epoch')\n",
    "plot_losses(logs, methods, ax=axes[2], log='kl', ylabel='KL', xlabel='iteration')\n",
    "plot_losses(logs, methods, ax=axes[3], log='rec_loss', ylabel='reconstruction loss', xlabel='iteration')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
